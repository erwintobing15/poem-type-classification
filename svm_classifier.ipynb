{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34c1c1be",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10a75543",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teks</th>\n",
       "      <th>jenis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jikalau kita bertanam padi \\n Senanglah makan ...</td>\n",
       "      <td>pantun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kalau ada air bersih \\n Bolehlah kita mengguna...</td>\n",
       "      <td>pantun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Buah Hatiku \\n Satu... \\n perlahan hadir... \\n...</td>\n",
       "      <td>puisi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anak ayam turun sepuluh \\n Mati satu tinggal s...</td>\n",
       "      <td>pantun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kala dulu \\n Ada sungai mengalir air \\n Selalu...</td>\n",
       "      <td>puisi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                teks   jenis\n",
       "0  Jikalau kita bertanam padi \\n Senanglah makan ...  pantun\n",
       "1  Kalau ada air bersih \\n Bolehlah kita mengguna...  pantun\n",
       "2  Buah Hatiku \\n Satu... \\n perlahan hadir... \\n...   puisi\n",
       "3  Anak ayam turun sepuluh \\n Mati satu tinggal s...  pantun\n",
       "4  Kala dulu \\n Ada sungai mengalir air \\n Selalu...   puisi"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('dataset.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4699374c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data train and data test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data['teks']\n",
    "y = data['jenis']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8e5519",
   "metadata": {},
   "source": [
    "### Vectorizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8722bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create feature vectors\n",
    "vectorizer = TfidfVectorizer(min_df = 5,\n",
    "                             max_df = 0.8,\n",
    "                             sublinear_tf = True,\n",
    "                             use_idf = True)\n",
    "train_vectors = vectorizer.fit_transform(X_train)\n",
    "test_vectors = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f043d8be",
   "metadata": {},
   "source": [
    "### Creating a Linear SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3fc5656",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Perform classification with SVM, kernel=linear\n",
    "classifier_linear = svm.SVC(kernel='linear',probability=True)\n",
    "t0 = time.time()\n",
    "classifier_linear.fit(train_vectors, y_train)\n",
    "t1 = time.time()\n",
    "prediction_linear = classifier_linear.predict(test_vectors)\n",
    "t2 = time.time()\n",
    "time_linear_train = t1-t0\n",
    "time_linear_predict = t2-t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c91a4f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.616604s; Prediction time: 0.017993s\n",
      "pantun:  {'precision': 0.9538461538461539, 'recall': 0.9841269841269841, 'f1-score': 0.96875, 'support': 63}\n",
      "puisi:  {'precision': 0.9850746268656716, 'recall': 0.9565217391304348, 'f1-score': 0.9705882352941176, 'support': 69}\n"
     ]
    }
   ],
   "source": [
    "# results\n",
    "print(\"Training time: %fs; Prediction time: %fs\" % (time_linear_train, time_linear_predict))\n",
    "report = classification_report(y_test, prediction_linear, output_dict=True)\n",
    "print('pantun: ', report['pantun'])\n",
    "print('puisi: ', report['puisi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab5ea1e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['pantun', 'puisi', 'puisi', 'pantun', 'pantun', 'puisi', 'puisi',\n",
       "       'pantun', 'pantun', 'puisi', 'puisi', 'pantun', 'puisi', 'pantun',\n",
       "       'pantun', 'puisi', 'puisi', 'pantun', 'pantun', 'puisi', 'puisi',\n",
       "       'puisi', 'puisi', 'puisi', 'puisi', 'puisi', 'puisi', 'puisi',\n",
       "       'pantun', 'pantun', 'puisi', 'pantun', 'pantun', 'puisi', 'pantun',\n",
       "       'pantun', 'puisi', 'puisi', 'pantun', 'puisi', 'pantun', 'pantun',\n",
       "       'puisi', 'pantun', 'pantun', 'pantun', 'pantun', 'puisi', 'puisi',\n",
       "       'puisi', 'puisi', 'puisi', 'pantun', 'pantun', 'puisi', 'pantun',\n",
       "       'pantun', 'puisi', 'puisi', 'puisi', 'puisi', 'puisi', 'pantun',\n",
       "       'puisi', 'pantun', 'pantun', 'puisi', 'pantun', 'pantun', 'pantun',\n",
       "       'pantun', 'puisi', 'puisi', 'pantun', 'pantun', 'pantun', 'puisi',\n",
       "       'pantun', 'puisi', 'puisi', 'puisi', 'puisi', 'pantun', 'pantun',\n",
       "       'puisi', 'puisi', 'puisi', 'puisi', 'pantun', 'puisi', 'pantun',\n",
       "       'pantun', 'puisi', 'puisi', 'puisi', 'pantun', 'puisi', 'pantun',\n",
       "       'pantun', 'pantun', 'pantun', 'pantun', 'puisi', 'puisi', 'pantun',\n",
       "       'pantun', 'puisi', 'pantun', 'puisi', 'puisi', 'puisi', 'puisi',\n",
       "       'pantun', 'pantun', 'puisi', 'puisi', 'pantun', 'pantun', 'pantun',\n",
       "       'puisi', 'pantun', 'pantun', 'puisi', 'puisi', 'puisi', 'pantun',\n",
       "       'pantun', 'pantun', 'pantun', 'pantun', 'pantun', 'puisi'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7343001e",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05fae7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['puisi']\n"
     ]
    }
   ],
   "source": [
    "teks = \"\"\"Perlahan menipis gumpalan\n",
    "Awan langit memutih\n",
    "Tergenang di kolam penampungan\n",
    "Sorot mata bocah pengungsi\n",
    "Berbinar binar\n",
    "Sepanjang jalan bersorak sorak\n",
    "Basah badan menarik gerobak\n",
    "Jirigen jirigen air tertata rapi\n",
    "Tanah kita tak kering lagi\n",
    "Hujan telah kembali\"\"\"\n",
    "\n",
    "teks_vector = vectorizer.transform([teks]) # vectorizing\n",
    "print(classifier_linear.predict(teks_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f2e1bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.21298043 0.78701957]]\n"
     ]
    }
   ],
   "source": [
    "print(classifier_linear.predict_proba(teks_vector))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50daa577",
   "metadata": {},
   "source": [
    "### Pickling the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b936eff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# pickling the vectorizer\n",
    "pickle.dump(vectorizer, open('vectorizer.sav', 'wb'))\n",
    "\n",
    "# pickling the model\n",
    "pickle.dump(classifier_linear, open('classifier.sav', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
